# Lesson 19: Dropout and Introduction to Diffusion Models

## Transition to Diffusion Models
- Demo on DDPM (Denoising Diffusion Probabilistic Models).
- Goal: build DDPM from scratch using miniai, except for U-Net model.
- Unconditional DDPM: no control over generated image types.

## DDPM Overview
- Uses miniai to implement diffusion model from 2020 DDPM paper.
- Paper simplified diffusion models, improved results on CIFAR-10, faces.
- Diffusion models: add noise (forward process), learn to denoise (reverse process).
- Forward process: iteratively adds noise to images until pure noise.
- Reverse process: neural network predicts noise to reconstruct image.

## Generative Modeling Context
- Goal: model data distribution (p(x)) to generate new samples (e.g., images).
- Example: height distribution, sampling realistic heights.
- Approaches: GANs, VAEs, diffusion models (or iterative refinement).
- Diffusion models currently popular, but new non-diffusion models emerging.

## DDPM Math and Variables
- Forward process: adds Gaussian noise, controlled by beta-t (increases variance).
- Alpha-bar-t: decreases contribution of original image over time.
- Reverse process: neural network predicts noise (epsilon-theta) using MSE loss.
- Simplified training: noise prediction instead of direct image reconstruction.
- Noise prediction guides iterative refinement toward data distribution.

## DDPM Implementation in miniai
- Uses Fashion-MNIST dataset, U-Net from Hugging Face Diffusers (temporary).
- Training: adds noise at random timesteps, predicts noise with MSE loss.
- Callback (DDPMCB): sets up noisy image, timestep, and noise target.
- Custom predict method: unpacks batch tuple, handles Diffusers’ .sample output.
- Training loop: standard miniai with DDPM callback, MSE loss, scheduler.

## Sampling Process
- Starts with pure noise, iteratively denoises using noise predictions.
- Predicts denoised image (x0_hat), blends with noisy image, adds noise.
- Coefficients adjust weighting: more denoised estimate as timesteps decrease.
- Results: decent Fashion-MNIST images after 5 epochs, 4-minute training.

## Visualizing Sampling
- Tracks sampling over timesteps, shows transition from noise to image.
- Limitation: original DDPM noise schedule (linear beta) inefficient for small images.
- Most change occurs after timestep 800; earlier steps mostly noise.
- Improved schedules (e.g., from improved DDPM paper) suggested for exploration.

## Jeremy’s Experiments (Notebook 17)
- Visualized real Fashion-MNIST images for comparison.
- Refactored DDPM callback: extracted noisify and sample functions for flexibility.
- Alternative approach: inherited from Callback, wrapped U-Net to avoid TrainCB.
- Optimizations: halved U-Net channels, adjusted group norm, custom weight initialization.
- Used mixed precision for speed (to be covered in Lesson 20).

## Conclusion
- Fashion-MNIST classification improved via Dropout; now targeting generative modeling.
- DDPM implemented from scratch (except U-Net), achieving decent results.
- Next steps: improve noise schedules, explore faster training, and tackle U-Net.
- Community challenge: enhance Fashion-MNIST generation, aim for harder datasets.