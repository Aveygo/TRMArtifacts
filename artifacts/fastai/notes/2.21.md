# Lesson 21: miniai and Diffusion Models

## Scaling Up with CIFAR-10
- Transition from Fashion-MNIST to CIFAR-10 dataset.
- CIFAR-10: popular for image classification and generative modeling.
- Challenges: low-resolution images (32x32, 3 channels) hard to evaluate visually.
- Same miniai code used, adapted for 3-channel images.
- Issues with CIFAR-10: difficult to distinguish generated images; metric needed.

## Experiment Tracking with Weights and Biases (W&B)
- Motivation: track experiments, monitor samples over epochs.
- W&B setup: free for personal/academic use, logs metrics, samples, code.
- Benefits: remote monitoring, collaborative sharing, reproducible runs.
- Implementation: custom callback logs loss, samples to W&B.
- Jeremy’s view: prefers directed experiments over extensive hyperparameter sweeps.

## Evaluating Generated Images: FID and KID
- Problem: assessing quality of generated images.
- FID (Fréchet Inception Distance):
  - Compares feature distributions (means, covariance) between real and generated images.
  - Uses pre-trained classifier (Fashion-MNIST-specific, not Inception).
  - Caveats: biased with fewer samples, resizing issues with Inception.
- KID (Kernel Inception Distance):
  - Unbiased but high variance, less reliable.
- Implementation: ImageEval class for consistent FID/KID calculation.

## Bug Fixing and Discoveries
- Bug: images scaled 0 to 1 instead of -1 to 1.
- Fix attempt (-1 to 1) worsened results, revealing no foundational reason for standard range.
- Solution: scale to -0.5 to 0.5 improved FID dramatically.
- Lesson: bugs can lead to accidental discoveries if investigated carefully.

## Improving Schedules
- Default linear schedule (betamax=0.02) problematic: flat regions.
- Cosine schedule smoother, better slope; Stable Diffusion uses betamax=0.012.
- Experiment: betamax=0.01 mimics cosine schedule, improves results.
- Outcome: better FID with linear schedule tweak.

## Faster Sampling with DDIM
- Goal: reduce sampling time without retraining.
- DDIM (Denoising Diffusion Implicit Models):
  - Faster sampling (e.g., 333 steps vs. 1000).
  - Deterministic option (eta=0), same model as DDPM.
  - Simpler equations, fewer parameters (alpha bar only).
- Implementation: adapted diffusers’ DDIM, then custom version.
- Results: FID comparable to DDPM at 200 steps, degrades at 25 steps (smoother images).

## DDIM vs. DDPM: Technical Insights
- DDPM: predicts noise, adds fixed noise per step.
- DDIM: introduces sigma (eta) to control noise, enables deterministic sampling.
- Notation issues: DDIM’s alpha is DDPM’s alpha bar.
- Advantage: DDIM’s flexibility with fewer steps, easier with cosine schedule.

## Conclusion
- Achieved near-real FID for Fashion-MNIST with DDPM/DDIM.
- Moving beyond Stable Diffusion: exploring new research directions.
- Experiment tracking (W&B) and metrics (FID) critical for progress.
- Next steps: UNet architectures, advanced sampling techniques.
